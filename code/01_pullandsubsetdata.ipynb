{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da82990e",
   "metadata": {},
   "source": [
    "Plan of attack: \n",
    "\n",
    "-Subset THE DEMOGRAPHICS dataset by: \n",
    "Gender (Male/Female)\n",
    "Race \n",
    "\n",
    "-Merge the demographics data and the Start FEIS data by patient ID # \n",
    "-Clean data so only relevant columns are left (Demographic data + family input)\n",
    "\n",
    "We plan firstly to look at the spectrum of responses comparing available services/client mental health (as the answers are on a scale) and turn this into numerical data in order to quantify the quality of each subset’s degree of care.\n",
    "\n",
    "We then plan to conduct topic modeling on the column in which families discuss where care is lacking in order to find the most popular/most desired methods of care that START did not provide. \n",
    "\n",
    "We also plan to conduct topic modeling and sentiment analysis on the column in which families offer advice to their caregiver in order to form a rough idea of the quality of care and how it may vary across demographic groups. We also are interested to see if these responses’ sentiment scores will trend in a specific direction, indicating biases in those who actually responded to the survey.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c455bebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/veronicaquidore/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/veronicaquidore/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing modules\n",
    "## helpful packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "\n",
    "## nltk imports\n",
    "import nltk\n",
    "### uncomment and run these lines if you haven't downloaded relevant nltk add-ons yet\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('stopwords')\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "## spacy imports\n",
    "import spacy\n",
    "### uncomment and run the below line if you haven't loaded the en_core_web_sm library yet\n",
    "#! python -m spacy download en_core_web_sm\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "## vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "## sentiment\n",
    "#!pip install vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "## lda\n",
    "from gensim import corpora\n",
    "import gensim\n",
    "\n",
    "## repeated printouts and wide-format text\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8ab51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = pd.read_excel(r\"../files/Dartmouth_Data_Set.xlsx\")\n",
    "FEIS_df = pd.read_excel(r\"../files/START_FEIS_Data.xlsx\")\n",
    "time_df = pd.read_excel(r\"../files/Dartmouth_Time_Data.xlsx\")\n",
    "dict_df = pd.read_excel(r\"../files/Final SIRS_Data_Dictionary_V13.1 October 2020.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a0f57b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the demographics dataset\n",
    "demographics = demo_df[['Local ID', 'Region', 'Date Enrolled in START', 'Gender', 'Race', 'Date of birth', 'Ethnicity',\n",
    "                              'Level of Intellectual Disability', 'Psychiatric diagnoses', 'Medical diagnoses', 'Other Disabilities',\n",
    "                              'Funding']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e097763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0        8008815\n",
       "1        6570649\n",
       "2         434021\n",
       "3        6580618\n",
       "4         354280\n",
       "          ...   \n",
       "1092     1013197\n",
       "1093     1100502\n",
       "1094     1132230\n",
       "1095    11128011\n",
       "1096    11124353\n",
       "Name: Local ID, Length: 1097, dtype: object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1097, 69)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging datasets\n",
    "merged = pd.merge(demographics, FEIS_df, how = 'inner', left_on = ['Local ID'], right_on = ['Respondent ID #  (SIRS Local ID)'])\n",
    "\n",
    "# Look at type of join (changed)\n",
    "\n",
    "merged['Local ID'].unique\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a813cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local ID</th>\n",
       "      <th>Region</th>\n",
       "      <th>Date Enrolled in START</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Date of birth</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Level of Intellectual Disability</th>\n",
       "      <th>Psychiatric diagnoses</th>\n",
       "      <th>Medical diagnoses</th>\n",
       "      <th>...</th>\n",
       "      <th>In\\nthe past year, did your family member use in-patient psychiatric services?</th>\n",
       "      <th>If\\nyes, were the inpatient services that your family member received helpful to\\nhim/her in your opinion?  ?</th>\n",
       "      <th>How\\nmuch help was available to you at night or on weekends if your family member\\nhad a crisis?</th>\n",
       "      <th>Are\\nthere options outside of the hospital for individuals experiencing a crisis to\\ngo for help (i.e. crisis/hospital diversion beds)?</th>\n",
       "      <th>Who\\nwas the primary source of information about your family memberâ€™s mental health\\nservices?</th>\n",
       "      <th>If other, please describe..2</th>\n",
       "      <th>During the past year, how much involvement\\ndid you want to have in your family memberâ€™s treatment plan?</th>\n",
       "      <th>Was there any particular service that your\\nfamily member needed that was not available?</th>\n",
       "      <th>If yes, please describe the service.</th>\n",
       "      <th>What\\nadvice would you give to service planners regarding the mental health service\\nneeds of persons with IDD and their families?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>434021</td>\n",
       "      <td>New York : Region 3</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>2001-12-24</td>\n",
       "      <td>Not of Hispanic origin</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Attention-Deficit/Hyperactivity Disorder, Autism Spectrum Disorder, Oppositional Defiant Disorder, Social Anxiety Disorder</td>\n",
       "      <td>Gastro/Intestinal</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None at all</td>\n",
       "      <td>None at all</td>\n",
       "      <td>His/her psychiatrist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A lot</td>\n",
       "      <td>Yes</td>\n",
       "      <td>In-home behavior support</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21347</td>\n",
       "      <td>Texas : Tarrant County</td>\n",
       "      <td>2020-12-14</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>1991-09-15</td>\n",
       "      <td>Hispanic - specific origin not specified</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Endocrine</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>None at all</td>\n",
       "      <td>All that was wanted/needed</td>\n",
       "      <td>Did not know/answer</td>\n",
       "      <td>Other</td>\n",
       "      <td>Casa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8146562</td>\n",
       "      <td>California : CA START East Bay</td>\n",
       "      <td>2020-12-09</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>2006-10-03</td>\n",
       "      <td>Not of Hispanic origin</td>\n",
       "      <td>Mild</td>\n",
       "      <td>Autism Spectrum Disorder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Very little</td>\n",
       "      <td>None at all</td>\n",
       "      <td>His/her psychiatrist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A lot</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good psychiatry, crisis help that was more hands on, caregivers/ respite workers, etc.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7697408</td>\n",
       "      <td>California : CA START Westside</td>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>1993-03-16</td>\n",
       "      <td>Unknown, not collected</td>\n",
       "      <td>Borderline</td>\n",
       "      <td>Attention-Deficit/Hyperactivity Disorder, Autism Spectrum Disorder</td>\n",
       "      <td>Obesity, Other: Asthma; had asthma when she was younger</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Very little</td>\n",
       "      <td>All that was wanted/needed</td>\n",
       "      <td>All that was wanted/needed</td>\n",
       "      <td>Your family member him/herself</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A lot</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mental Health Services, individual therapy</td>\n",
       "      <td>Harlee can create fabricated stories based off information she received from mental health providers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>359313</td>\n",
       "      <td>New York : Region 3</td>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Not of Hispanic origin</td>\n",
       "      <td>Normal intelligence</td>\n",
       "      <td>Attention-Deficit/Hyperactivity Disorder, Autism Spectrum Disorder, Oppositional Defiant Disorder</td>\n",
       "      <td>Pulmonary disorders</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None at all</td>\n",
       "      <td>Did not know/answer</td>\n",
       "      <td>Other</td>\n",
       "      <td>Grandmother</td>\n",
       "      <td>A lot</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family had no information form their assigned social worker from a community agency and felf uninformed.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Local ID                          Region Date Enrolled in START  Gender  \\\n",
       "2    434021             New York : Region 3             2020-12-28  Female   \n",
       "9     21347          Texas : Tarrant County             2020-12-14  Female   \n",
       "10  8146562  California : CA START East Bay             2020-12-09  Female   \n",
       "21  7697408  California : CA START Westside             2020-11-20  Female   \n",
       "33   359313             New York : Region 3             2020-11-16  Female   \n",
       "\n",
       "     Race Date of birth                                 Ethnicity  \\\n",
       "2   White    2001-12-24                    Not of Hispanic origin   \n",
       "9   White    1991-09-15  Hispanic - specific origin not specified   \n",
       "10  White    2006-10-03                    Not of Hispanic origin   \n",
       "21  White    1993-03-16                    Unknown, not collected   \n",
       "33  White    2008-12-03                    Not of Hispanic origin   \n",
       "\n",
       "   Level of Intellectual Disability  \\\n",
       "2                        Borderline   \n",
       "9                          Moderate   \n",
       "10                             Mild   \n",
       "21                       Borderline   \n",
       "33              Normal intelligence   \n",
       "\n",
       "                                                                                                         Psychiatric diagnoses  \\\n",
       "2   Attention-Deficit/Hyperactivity Disorder, Autism Spectrum Disorder, Oppositional Defiant Disorder, Social Anxiety Disorder   \n",
       "9                                                                                                                          NaN   \n",
       "10                                                                                                    Autism Spectrum Disorder   \n",
       "21                                                          Attention-Deficit/Hyperactivity Disorder, Autism Spectrum Disorder   \n",
       "33                           Attention-Deficit/Hyperactivity Disorder, Autism Spectrum Disorder, Oppositional Defiant Disorder   \n",
       "\n",
       "                                           Medical diagnoses  ...  \\\n",
       "2                                          Gastro/Intestinal  ...   \n",
       "9                                                  Endocrine  ...   \n",
       "10                                                       NaN  ...   \n",
       "21  Obesity, Other: Asthma; had asthma when she was younger   ...   \n",
       "33                                       Pulmonary disorders  ...   \n",
       "\n",
       "   In\\nthe past year, did your family member use in-patient psychiatric services?  \\\n",
       "2                                                                              No   \n",
       "9                                                                              No   \n",
       "10                                                                             No   \n",
       "21                                                                            Yes   \n",
       "33                                                                             No   \n",
       "\n",
       "   If\\nyes, were the inpatient services that your family member received helpful to\\nhim/her in your opinion?  ?  \\\n",
       "2                                                                                                            NaN   \n",
       "9                                                                                                    None at all   \n",
       "10                                                                                                           NaN   \n",
       "21                                                                                                   Very little   \n",
       "33                                                                                                           NaN   \n",
       "\n",
       "   How\\nmuch help was available to you at night or on weekends if your family member\\nhad a crisis?  \\\n",
       "2                                                                                       None at all   \n",
       "9                                                                        All that was wanted/needed   \n",
       "10                                                                                      Very little   \n",
       "21                                                                       All that was wanted/needed   \n",
       "33                                                                                      None at all   \n",
       "\n",
       "   Are\\nthere options outside of the hospital for individuals experiencing a crisis to\\ngo for help (i.e. crisis/hospital diversion beds)?  \\\n",
       "2                                                                                                                              None at all   \n",
       "9                                                                                                                      Did not know/answer   \n",
       "10                                                                                                                             None at all   \n",
       "21                                                                                                              All that was wanted/needed   \n",
       "33                                                                                                                     Did not know/answer   \n",
       "\n",
       "   Who\\nwas the primary source of information about your family memberâ€™s mental health\\nservices?  \\\n",
       "2                                                                              His/her psychiatrist   \n",
       "9                                                                                             Other   \n",
       "10                                                                             His/her psychiatrist   \n",
       "21                                                                   Your family member him/herself   \n",
       "33                                                                                            Other   \n",
       "\n",
       "   If other, please describe..2  \\\n",
       "2                           NaN   \n",
       "9                          Casa   \n",
       "10                          NaN   \n",
       "21                          NaN   \n",
       "33                  Grandmother   \n",
       "\n",
       "   During the past year, how much involvement\\ndid you want to have in your family memberâ€™s treatment plan?  \\\n",
       "2                                                                                                       A lot   \n",
       "9                                                                                                         NaN   \n",
       "10                                                                                                      A lot   \n",
       "21                                                                                                      A lot   \n",
       "33                                                                                                      A lot   \n",
       "\n",
       "   Was there any particular service that your\\nfamily member needed that was not available?  \\\n",
       "2                                                                                       Yes   \n",
       "9                                                                                        No   \n",
       "10                                                                                      Yes   \n",
       "21                                                                                      Yes   \n",
       "33                                                                                       No   \n",
       "\n",
       "                                                      If yes, please describe the service.  \\\n",
       "2                                                                In-home behavior support    \n",
       "9                                                                                      NaN   \n",
       "10  Good psychiatry, crisis help that was more hands on, caregivers/ respite workers, etc.   \n",
       "21                                             Mental Health Services, individual therapy    \n",
       "33                                                                                     NaN   \n",
       "\n",
       "   What\\nadvice would you give to service planners regarding the mental health service\\nneeds of persons with IDD and their families?  \n",
       "2                                                                                                                                 NaN  \n",
       "9                                                                                                                                 NaN  \n",
       "10                                                                                                                                NaN  \n",
       "21                             Harlee can create fabricated stories based off information she received from mental health providers.   \n",
       "33                           Family had no information form their assigned social worker from a community agency and felf uninformed.  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subsetting by gender\n",
    "demographics_male = merged.loc[merged['Gender']=='Male']\n",
    "demographics_female = merged.loc[merged['Gender']=='Female']\n",
    "\n",
    "# Subsetting by race\n",
    "male_white = demographics_male[demographics_male['Race'] == \"White\"]\n",
    "male_nonwhite = demographics_male[demographics_male['Race'] != \"White\"]\n",
    "\n",
    "female_white = demographics_female[demographics_female['Race'] == \"White\"]\n",
    "female_nonwhite = demographics_female[demographics_female['Race'] != \"White\"]\n",
    "\n",
    "\n",
    "#male_white.shape\n",
    "#male_nonwhite.shape\n",
    "\n",
    "female_white.head()\n",
    "#female_nonwhite.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bce9ab4",
   "metadata": {},
   "source": [
    "## Export CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43429a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "male_white_csv = male_white.to_csv(\"../output/male_white\", index=False)\n",
    "male_white_csv\n",
    "\n",
    "male_nonwhite_csv = male_nonwhite.to_csv(\"../output/male_nonwhite\", index=False)\n",
    "male_nonwhite_csv\n",
    "\n",
    "female_white_csv = female_white.to_csv(\"../output/female_white\", index=False)\n",
    "female_white_csv\n",
    "\n",
    "female_nonwhite_csv = female_nonwhite.to_csv(\"../output/female_nonwhite\", index=False)\n",
    "female_nonwhite_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dce7cf4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/veronicaquidore/nltk_data'\n    - '/Users/veronicaquidore/opt/anaconda3/nltk_data'\n    - '/Users/veronicaquidore/opt/anaconda3/share/nltk_data'\n    - '/Users/veronicaquidore/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3l/pdqq6kxn41j1l7vxkjmbbc5w0000gn/T/ipykernel_7573/1324086714.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0madvice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processed_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madvice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Advice\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0madvice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/3l/pdqq6kxn41j1l7vxkjmbbc5w0000gn/T/ipykernel_7573/1324086714.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0madvice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processed_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madvice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Advice\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0madvice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/3l/pdqq6kxn41j1l7vxkjmbbc5w0000gn/T/ipykernel_7573/1324086714.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mstring_lower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#string_lower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring_lower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtokenize_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#tokenize_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/Users/veronicaquidore/nltk_data'\n    - '/Users/veronicaquidore/opt/anaconda3/nltk_data'\n    - '/Users/veronicaquidore/opt/anaconda3/share/nltk_data'\n    - '/Users/veronicaquidore/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# female_white.head()\n",
    "female_white_subset = female_white[['Local ID','What\\nadvice would you give to service planners regarding the mental health service\\nneeds of persons with IDD and their families?', \"Was there any particular service that your\\nfamily member needed that was not available?\", \"If yes, please describe the service.\"]]\n",
    "female_white_subset.columns = ['ID', 'Advice', 'Missing Service', 'Service Needed']\n",
    "\n",
    "advice = female_white_subset[[\"ID\", \"Advice\"]]\n",
    "advice = advice.dropna()\n",
    "#advice.head()adv\n",
    "# female_white_subset.head()\n",
    "\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "snowball = SnowballStemmer(language=\"english\")\n",
    "\n",
    "def process(string):\n",
    "    string_lower = string.lower()\n",
    "    #string_lower\n",
    "    tokens = word_tokenize(string_lower)\n",
    "    tokenize_string = [s for s in tokens if not s.lower() in stop_words]\n",
    "    #tokenize_string\n",
    "    alpha_string = [re.sub('[^A-Za-z]+', '', s) for s in tokenize_string]\n",
    "    #alpha_string\n",
    "    stem_string = [snowball.stem(s) for s in alpha_string]\n",
    "    #stem_string\n",
    "    final_string = \" \".join(stem_string)\n",
    "    #final_string\n",
    "    return final_string\n",
    "\n",
    "advice['processed_text'] = [process(string) for string in advice[\"Advice\"]]\n",
    "advice\n",
    "\n",
    "\n",
    "\n",
    "# female_white_subset['Advice']\n",
    "\n",
    "# female_white[\"What\\nadvice would you give to service planners regarding the mental health service\\nneeds of persons with IDD and their families?\"]\n",
    "# female_white[\"Was there any particular service that your\\nfamily member needed that was not available?\"]\n",
    "# female_white[\"If yes, please describe the service.\"]\n",
    "# # what advice would you give and \n",
    "\n",
    "# if services are not easy to access, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8590e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the document-term matrix \n",
    "\n",
    "def create_dtm(list_of_strings, metadata):\n",
    "    vectorizer = CountVectorizer(lowercase = True)\n",
    "    dtm_sparse = vectorizer.fit_transform(list_of_strings)\n",
    "    dtm_dense_named = pd.DataFrame(dtm_sparse.todense(),\n",
    "                columns=vectorizer.get_feature_names())\n",
    "    metadata.columns = [\"metadata_\" + col for col in metadata.columns]\n",
    "    dtm_dense_named_withid = pd.concat([metadata.reset_index(), \n",
    "                                        dtm_dense_named], axis = 1)\n",
    "    return(dtm_dense_named_withid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fff876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "dtm_nopre = create_dtm(list_of_strings= advice['processed_text'],\n",
    "                metadata = \n",
    "                advice[[\"ID\"]])\n",
    "\n",
    "dtm_nopre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d408e06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topwords(dtm): \n",
    "    topdtm = dtm[[col for col in dtm.columns\n",
    "               if 'metadata' not in col and col != 'index']].sum(axis=0)\n",
    "    return topdtm.sort_values(ascending=False).head(30)\n",
    "\n",
    "\n",
    "print(\"Top words for Advice\")\n",
    "get_topwords(dtm_nopre)\n",
    "\n",
    "# Justifying not dropping named entities - none really came up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff191489",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_raw_tokens = [wordpunct_tokenize(s) \n",
    "                for s in \n",
    "                advice['processed_text']]\n",
    "\n",
    "text_raw_dict = corpora.Dictionary(text_raw_tokens)\n",
    "\n",
    "corpus_fromdict = [text_raw_dict.doc2bow(s) \n",
    "                   for s in text_raw_tokens]\n",
    "\n",
    "ldamod = gensim.models.ldamodel.LdaModel(corpus_fromdict, \n",
    "                                num_topics = 3, id2word=text_raw_dict, \n",
    "                                passes=6, alpha = 'auto',\n",
    "                                per_word_topics = True, random_state = 2)\n",
    "\n",
    "topics = ldamod.print_topics(num_words = 30)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee4b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize - may not work on jhub yet\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "# alternate: import pyLDAvis.gensim_models as gensimvis \n",
    "import pyLDAvis\n",
    "#pyLDAvis.enable_notebook()\n",
    "lda_display = gensimvis.prepare(ldamod, corpus_fromdict, text_raw_dict)\n",
    "pyLDAvis.display(lda_display)\n",
    "\n",
    "### visualize\n",
    "pyLDAvis.enable_notebook()\n",
    "lda_display_proc = gensimvis.prepare(ldamod_proc, corpus_fromdict_proc, text_proc_dict)\n",
    "pyLDAvis.display(lda_display_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f39bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
